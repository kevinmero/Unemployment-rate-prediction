{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfBwJN1GaqNY"
      },
      "source": [
        "#### 1. Import the necessary modules\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfoGb_tJEWgZ"
      },
      "outputs": [],
      "source": [
        "!pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM_lTJ3LEXoH"
      },
      "outputs": [],
      "source": [
        "!pip install bitstring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AmDZ_oYEVi6J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "from keras.layers import LSTM, Input, Dense\n",
        "from keras.models import Model\n",
        "from deap import base, creator, tools, algorithms\n",
        "from scipy.stats import bernoulli\n",
        "from bitstring import BitArray\n",
        "np.random.seed(1120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex5UYn-mb6-G"
      },
      "source": [
        "#### 2. Import time series data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdtJoAsaVqMY"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/sample_data/desempleo.csv', sep=';')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HloNFlieWS-f"
      },
      "outputs": [],
      "source": [
        "cols = list(df)[2:6]\n",
        "print(cols)\n",
        "df_train = df[cols]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df_train)\n",
        "df_train_scaled = scaler.transform(df_train)\n",
        "\n",
        "train_data = df_train_scaled[0:194]\n",
        "test_data = df_train_scaled[194:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MTYzXJ-Y3Q2"
      },
      "source": [
        "#### 3. Prepare the data set according to the window size (windows_size) chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QcMiVylwLvYh"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(df_train_scaled, window_size):\n",
        "  X_train = []\n",
        "  Y_train = []\n",
        "  n_future = 1\n",
        "  number_of_features = 4\n",
        "\n",
        "  for i in range(window_size, len(df_train_scaled)-n_future+1):\n",
        "    X = X_train.append(df_train_scaled[i-window_size:i,0:number_of_features])\n",
        "    Y = Y_train.append(df_train_scaled[i+n_future-1:i+n_future,3])\n",
        "\n",
        "  X, Y = np.array(X_train), np.array(Y_train)\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sctNC2kEcI2Z"
      },
      "source": [
        "####4. The train_evaluate function creates the LSTM network for a given individual and returns the accuracy of the training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "kagsVfA0wHUb"
      },
      "outputs": [],
      "source": [
        "def train_evaluate(ga_individual_solution):\n",
        "    window_size_bits = BitArray(ga_individual_solution[0:5])\n",
        "    num_units_bits = BitArray(ga_individual_solution[5:])\n",
        "    window_size = window_size_bits.uint\n",
        "    num_units = num_units_bits.uint\n",
        "    print('\\nWindow Size: ', window_size, ', Num of Units: ', num_units)\n",
        "    print (ga_individual_solution)\n",
        "    if window_size == 0 or num_units == 0:\n",
        "        return 100,\n",
        "    X,Y = prepare_dataset(train_data,window_size)\n",
        "    X_train, X_val, y_train, y_val = split(X, Y, test_size = 0.10, random_state = 1120)\n",
        "    inputs = Input(shape=(window_size,4))\n",
        "    x = LSTM(num_units, input_shape=(window_size,4))(inputs)\n",
        "    predictions = Dense(1, activation='linear')(x)\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    print(model.summary())\n",
        "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=10, shuffle=True)\n",
        "    y_pred = model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print('Validation RMSE: ', rmse,'\\n')\n",
        "    return rmse,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQAIYmTayse"
      },
      "source": [
        "####5. Use the DEAP tool to define the individual (since the chromosome is represented by 9 bits, the Bernoulli distribution is used). Create the population, use ordered mating, use mutShuffleIndexes mutation, and use spinner selection for parental selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaA30bM0xFlM"
      },
      "outputs": [],
      "source": [
        "population_size = 4\n",
        "num_generations = 10\n",
        "gene_length = 9\n",
        "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
        "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
        "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register('mate', tools.cxOrdered)\n",
        "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
        "toolbox.register('select', tools.selRoulette)\n",
        "toolbox.register('evaluate', train_evaluate)\n",
        "population = toolbox.population(n = population_size)\n",
        "r = algorithms.eaSimple(population, toolbox, cxpb = 0.6, mutpb = 0.4, ngen = num_generations, verbose = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4skfMbacWhP"
      },
      "source": [
        "#### 6. Get the best solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juyUUXZnxFp0"
      },
      "outputs": [],
      "source": [
        "best_individuals = tools.selBest(population,k = 1)\n",
        "best_window_size = None\n",
        "best_num_units = None\n",
        "\n",
        "for bi in best_individuals:\n",
        "    window_size_bits = BitArray(bi[0:5])\n",
        "    num_units_bits = BitArray(bi[5:]) \n",
        "    best_window_size = window_size_bits.uint\n",
        "    best_num_units = num_units_bits.uint\n",
        "    print (best_individuals, '\\n')\n",
        "    print('\\nWindow Size: ', best_window_size, ', Num of Units: ', best_num_units)\n",
        "    print ('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpMAdMA1ce43"
      },
      "source": [
        "#### 7. Implement the best solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR5eNnP_pbKw"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = prepare_dataset(train_data,best_window_size)\n",
        "X_test, y_test = prepare_dataset(test_data,best_window_size)\n",
        "inputs = Input(shape=(best_window_size,4))\n",
        "x = LSTM(best_num_units, input_shape=(best_window_size,4))(inputs)\n",
        "predictions = Dense(1, activation='linear')(x)\n",
        "model = Model(inputs = inputs, outputs = predictions)\n",
        "print(model.summary())\n",
        "model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "history=model.fit(X_train, y_train, epochs=5, batch_size=10, validation_split=0.1, verbose=1, shuffle=True)\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print('Test RMSE: ', rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzAwCPcgkbXR"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='Traininig loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.legend()\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgaIVcph_434"
      },
      "source": [
        "#### 8. Graph the solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KziapPp6NArF"
      },
      "outputs": [],
      "source": [
        "y_test_copies = np.repeat(y_test, df_train.shape[1], axis=-1) \n",
        "y_test = scaler.inverse_transform(y_test_copies)[:,3]\n",
        "y_pred_copies = np.repeat(y_pred, df_train.shape[1], axis=-1)\n",
        "y_pred = scaler.inverse_transform(y_pred_copies)[:,3]\n",
        "y_pred = np.round(y_pred,2)\n",
        "\n",
        "train_dates = pd.to_datetime(df['date'])\n",
        "lim_batch=len(y_pred)\n",
        "fin=len(train_dates)\n",
        "inicio = (fin - lim_batch)\n",
        "lista = []\n",
        "\n",
        "for j in range(inicio,fin,1):\n",
        "  r=train_dates[j].strftime('%Y-%m')\n",
        "  lista.append(r)\n",
        "\n",
        "mapped = range(len(lista))\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(y_test, label=\"Real values\")\n",
        "plt.plot(y_pred, label=\"Predicted values\")\n",
        "plt.xticks(mapped, lista)\n",
        "lim_final = len(lista)\n",
        "plt.xlim(0, lim_final)\n",
        "max1 = np.round(max (y_test),0)\n",
        "max2 = np.round(max (y_pred),0)\n",
        "\n",
        "if (max1 >= max2):\n",
        "  limy = max1 + 1\n",
        "else:\n",
        "  limy = max2 + 1\n",
        "  \n",
        "plt.ylim(0, limy)\n",
        "plt.title(\"Prediction of the unemployment rate in Ecuador\")\n",
        "plt.xlabel(\"Months\")\n",
        "plt.ylabel(\"Unemployment rate (%)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
